{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6264691-362b-475b-9804-b8677bf04a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38d10a36-c6b7-4643-a3f3-9b051b2fe98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([0.019192584458555206,\n",
    " -0.00022676442170543876,\n",
    " 1.5254716889012698e-05,\n",
    " 2.3841795382395503e-07,\n",
    " -0.0011042889334979544,\n",
    " -6.288365346329705e-06,\n",
    " -0.0018542499695373138,\n",
    " -4.83395142053338e-05,\n",
    " -0.022102480157944693,\n",
    " 0.0014161981810819624,\n",
    " 2.308553514752586e-06,\n",
    " -0.003486188782560018,\n",
    " 0.004680028737504283,\n",
    " 0.00010911995249740514,\n",
    " 0.004057511263407254,\n",
    " -1.5363963170145212e-05,\n",
    " -5.794456927654679e-05,\n",
    " -0.0022792777920224994,\n",
    " -0.00016444912271770503,\n",
    " 0.00045869332810474783,\n",
    " 0.0014819484881146705,\n",
    " 0.004808782892826734,\n",
    " 0.0006599598338768741,\n",
    " 0.003964485623999151,\n",
    " 0.0,\n",
    " 0.054728638784145016,\n",
    " 0.0006419025937236776,\n",
    " 1.7281752347275692e-05,\n",
    " -5.96044138490015e-07,\n",
    " 0.014142611044399844,\n",
    " 0.0005226021125581681,\n",
    " -0.003626447373832477,\n",
    " -0.0058413692772880665,\n",
    " 0.002248851605115232,\n",
    " 0.00011543023916660289,\n",
    " 0.0011056402894494832])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99e56bd4-0c0e-4f88-a87d-3711b2f0eb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 36)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.values.reshape(-1,1).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5c86066-e9b0-4d38-903a-39a19f252be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MinMaxScaler().fit_transform(s.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71bdb4a0-9b00-4a36-a66c-daa2b7a42196",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = s.max()\n",
    "m = s.min()\n",
    "low = 0.0\n",
    "high = 0.0\n",
    "rng = M - m\n",
    "norm = colors.Normalize(m - (rng * low),\n",
    "                        M + (rng * high))\n",
    "normed = norm(s)\n",
    "normed1 = MinMaxScaler().fit_transform(s.values.reshape(-1, 1))\n",
    "c = [colors.rgb2hex(x) for x in plt.cm.get_cmap('PuBu')(normed)]\n",
    "c1 = [colors.rgb2hex(x) for x in plt.cm.get_cmap('PuBu')(normed1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dec6351b-1efb-42e7-a354-02291ebaae33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Transform features by scaling each feature to a given range.\n",
       "\n",
       "This estimator scales and translates each feature individually such\n",
       "that it is in the given range on the training set, e.g. between\n",
       "zero and one.\n",
       "\n",
       "The transformation is given by::\n",
       "\n",
       "    X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
       "    X_scaled = X_std * (max - min) + min\n",
       "\n",
       "where min, max = feature_range.\n",
       "\n",
       "This transformation is often used as an alternative to zero mean,\n",
       "unit variance scaling.\n",
       "\n",
       "Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "feature_range : tuple (min, max), default=(0, 1)\n",
       "    Desired range of transformed data.\n",
       "\n",
       "copy : bool, default=True\n",
       "    Set to False to perform inplace row normalization and avoid a\n",
       "    copy (if the input is already a numpy array).\n",
       "\n",
       "clip : bool, default=False\n",
       "    Set to True to clip transformed values of held-out data to\n",
       "    provided `feature range`.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "min_ : ndarray of shape (n_features,)\n",
       "    Per feature adjustment for minimum. Equivalent to\n",
       "    ``min - X.min(axis=0) * self.scale_``\n",
       "\n",
       "scale_ : ndarray of shape (n_features,)\n",
       "    Per feature relative scaling of the data. Equivalent to\n",
       "    ``(max - min) / (X.max(axis=0) - X.min(axis=0))``\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *scale_* attribute.\n",
       "\n",
       "data_min_ : ndarray of shape (n_features,)\n",
       "    Per feature minimum seen in the data\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *data_min_*\n",
       "\n",
       "data_max_ : ndarray of shape (n_features,)\n",
       "    Per feature maximum seen in the data\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *data_max_*\n",
       "\n",
       "data_range_ : ndarray of shape (n_features,)\n",
       "    Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *data_range_*\n",
       "\n",
       "n_samples_seen_ : int\n",
       "    The number of samples processed by the estimator.\n",
       "    It will be reset on new calls to fit, but increments across\n",
       "    ``partial_fit`` calls.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.preprocessing import MinMaxScaler\n",
       ">>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
       ">>> scaler = MinMaxScaler()\n",
       ">>> print(scaler.fit(data))\n",
       "MinMaxScaler()\n",
       ">>> print(scaler.data_max_)\n",
       "[ 1. 18.]\n",
       ">>> print(scaler.transform(data))\n",
       "[[0.   0.  ]\n",
       " [0.25 0.25]\n",
       " [0.5  0.5 ]\n",
       " [1.   1.  ]]\n",
       ">>> print(scaler.transform([[2, 2]]))\n",
       "[[1.5 0. ]]\n",
       "\n",
       "See Also\n",
       "--------\n",
       "minmax_scale : Equivalent function without the estimator API.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "NaNs are treated as missing values: disregarded in fit, and maintained in\n",
       "transform.\n",
       "\n",
       "For a comparison of the different scalers, transformers, and normalizers,\n",
       "see :ref:`examples/preprocessing/plot_all_scaling.py\n",
       "<sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/bert_analyzer/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MinMaxScaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c551bea-c27a-47f4-9388-a272aaeaabcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        MinMaxScaler\n",
       "\u001b[0;31mString form:\u001b[0m MinMaxScaler()\n",
       "\u001b[0;31mFile:\u001b[0m        ~/anaconda3/envs/bert_analyzer/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Transform features by scaling each feature to a given range.\n",
       "\n",
       "This estimator scales and translates each feature individually such\n",
       "that it is in the given range on the training set, e.g. between\n",
       "zero and one.\n",
       "\n",
       "The transformation is given by::\n",
       "\n",
       "    X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
       "    X_scaled = X_std * (max - min) + min\n",
       "\n",
       "where min, max = feature_range.\n",
       "\n",
       "This transformation is often used as an alternative to zero mean,\n",
       "unit variance scaling.\n",
       "\n",
       "Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "feature_range : tuple (min, max), default=(0, 1)\n",
       "    Desired range of transformed data.\n",
       "\n",
       "copy : bool, default=True\n",
       "    Set to False to perform inplace row normalization and avoid a\n",
       "    copy (if the input is already a numpy array).\n",
       "\n",
       "clip : bool, default=False\n",
       "    Set to True to clip transformed values of held-out data to\n",
       "    provided `feature range`.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "min_ : ndarray of shape (n_features,)\n",
       "    Per feature adjustment for minimum. Equivalent to\n",
       "    ``min - X.min(axis=0) * self.scale_``\n",
       "\n",
       "scale_ : ndarray of shape (n_features,)\n",
       "    Per feature relative scaling of the data. Equivalent to\n",
       "    ``(max - min) / (X.max(axis=0) - X.min(axis=0))``\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *scale_* attribute.\n",
       "\n",
       "data_min_ : ndarray of shape (n_features,)\n",
       "    Per feature minimum seen in the data\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *data_min_*\n",
       "\n",
       "data_max_ : ndarray of shape (n_features,)\n",
       "    Per feature maximum seen in the data\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *data_max_*\n",
       "\n",
       "data_range_ : ndarray of shape (n_features,)\n",
       "    Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *data_range_*\n",
       "\n",
       "n_samples_seen_ : int\n",
       "    The number of samples processed by the estimator.\n",
       "    It will be reset on new calls to fit, but increments across\n",
       "    ``partial_fit`` calls.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.preprocessing import MinMaxScaler\n",
       ">>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
       ">>> scaler = MinMaxScaler()\n",
       ">>> print(scaler.fit(data))\n",
       "MinMaxScaler()\n",
       ">>> print(scaler.data_max_)\n",
       "[ 1. 18.]\n",
       ">>> print(scaler.transform(data))\n",
       "[[0.   0.  ]\n",
       " [0.25 0.25]\n",
       " [0.5  0.5 ]\n",
       " [1.   1.  ]]\n",
       ">>> print(scaler.transform([[2, 2]]))\n",
       "[[1.5 0. ]]\n",
       "\n",
       "See Also\n",
       "--------\n",
       "minmax_scale : Equivalent function without the estimator API.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "NaNs are treated as missing values: disregarded in fit, and maintained in\n",
       "transform.\n",
       "\n",
       "For a comparison of the different scalers, transformers, and normalizers,\n",
       "see :ref:`examples/preprocessing/plot_all_scaling.py\n",
       "<sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = MinMaxScaler()\n",
    "m?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5e487e1-084f-4f94-b7d9-3d211c0c9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = plt.cm.get_cmap('PuBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a41e9e6-68fa-4fbc-b957-51efd310d825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8664975 , 0.85953095, 0.92373702, 1.        ],\n",
       "       [0.06934256, 0.4716955 , 0.70643599, 1.        ],\n",
       "       [0.01680892, 0.37763937, 0.59223376, 1.        ],\n",
       "       [0.01877739, 0.42094579, 0.66113033, 1.        ],\n",
       "       [0.12359862, 0.50712803, 0.72415225, 1.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm(np.random.rand(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad9bc952-6cbb-4ff8-8055-53a47eec5c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        MaskedArray\n",
       "\u001b[0;31mString form:\u001b[0m\n",
       "[1.         0.53658537 0.53658537 0.53658537 0.51219512 0.53658537\n",
       " 0.48780488 0.53658537 0.         0.56097561]\n",
       "\u001b[0;31mLength:\u001b[0m      10\n",
       "\u001b[0;31mFile:\u001b[0m        ~/anaconda3/envs/bert_analyzer/lib/python3.8/site-packages/numpy/ma/core.py\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "An array class with possibly masked values.\n",
       "\n",
       "Masked values of True exclude the corresponding element from any\n",
       "computation.\n",
       "\n",
       "Construction::\n",
       "\n",
       "  x = MaskedArray(data, mask=nomask, dtype=None, copy=False, subok=True,\n",
       "                  ndmin=0, fill_value=None, keep_mask=True, hard_mask=None,\n",
       "                  shrink=True, order=None)\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : array_like\n",
       "    Input data.\n",
       "mask : sequence, optional\n",
       "    Mask. Must be convertible to an array of booleans with the same\n",
       "    shape as `data`. True indicates a masked (i.e. invalid) data.\n",
       "dtype : dtype, optional\n",
       "    Data type of the output.\n",
       "    If `dtype` is None, the type of the data argument (``data.dtype``)\n",
       "    is used. If `dtype` is not None and different from ``data.dtype``,\n",
       "    a copy is performed.\n",
       "copy : bool, optional\n",
       "    Whether to copy the input data (True), or to use a reference instead.\n",
       "    Default is False.\n",
       "subok : bool, optional\n",
       "    Whether to return a subclass of `MaskedArray` if possible (True) or a\n",
       "    plain `MaskedArray`. Default is True.\n",
       "ndmin : int, optional\n",
       "    Minimum number of dimensions. Default is 0.\n",
       "fill_value : scalar, optional\n",
       "    Value used to fill in the masked values when necessary.\n",
       "    If None, a default based on the data-type is used.\n",
       "keep_mask : bool, optional\n",
       "    Whether to combine `mask` with the mask of the input data, if any\n",
       "    (True), or to use only `mask` for the output (False). Default is True.\n",
       "hard_mask : bool, optional\n",
       "    Whether to use a hard mask or not. With a hard mask, masked values\n",
       "    cannot be unmasked. Default is False.\n",
       "shrink : bool, optional\n",
       "    Whether to force compression of an empty mask. Default is True.\n",
       "order : {'C', 'F', 'A'}, optional\n",
       "    Specify the order of the array.  If order is 'C', then the array\n",
       "    will be in C-contiguous order (last-index varies the fastest).\n",
       "    If order is 'F', then the returned array will be in\n",
       "    Fortran-contiguous order (first-index varies the fastest).\n",
       "    If order is 'A' (default), then the returned array may be\n",
       "    in any order (either C-, Fortran-contiguous, or even discontiguous),\n",
       "    unless a copy is required, in which case it will be C-contiguous.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "\n",
       "The ``mask`` can be initialized with an array of boolean values\n",
       "with the same shape as ``data``.\n",
       "\n",
       ">>> data = np.arange(6).reshape((2, 3))\n",
       ">>> np.ma.MaskedArray(data, mask=[[False, True, False],\n",
       "...                               [False, False, True]])\n",
       "masked_array(\n",
       "  data=[[0, --, 2],\n",
       "        [3, 4, --]],\n",
       "  mask=[[False,  True, False],\n",
       "        [False, False,  True]],\n",
       "  fill_value=999999)\n",
       "\n",
       "Alternatively, the ``mask`` can be initialized to homogeneous boolean\n",
       "array with the same shape as ``data`` by passing in a scalar\n",
       "boolean value:\n",
       "\n",
       ">>> np.ma.MaskedArray(data, mask=False)\n",
       "masked_array(\n",
       "  data=[[0, 1, 2],\n",
       "        [3, 4, 5]],\n",
       "  mask=[[False, False, False],\n",
       "        [False, False, False]],\n",
       "  fill_value=999999)\n",
       "\n",
       ">>> np.ma.MaskedArray(data, mask=True)\n",
       "masked_array(\n",
       "  data=[[--, --, --],\n",
       "        [--, --, --]],\n",
       "  mask=[[ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "  fill_value=999999,\n",
       "  dtype=int64)\n",
       "\n",
       ".. note::\n",
       "    The recommended practice for initializing ``mask`` with a scalar\n",
       "    boolean value is to use ``True``/``False`` rather than\n",
       "    ``np.True_``/``np.False_``. The reason is :attr:`nomask`\n",
       "    is represented internally as ``np.False_``.\n",
       "\n",
       "    >>> np.False_ is np.ma.nomask\n",
       "    True\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9323552c-4ca2-4be0-b71e-2c072c505bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A class which, when called, linearly normalizes data into the\n",
       "``[0.0, 1.0]`` interval.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Parameters\n",
       "----------\n",
       "vmin, vmax : float or None\n",
       "    If *vmin* and/or *vmax* is not given, they are initialized from the\n",
       "    minimum and maximum value, respectively, of the first input\n",
       "    processed; i.e., ``__call__(A)`` calls ``autoscale_None(A)``.\n",
       "\n",
       "clip : bool, default: False\n",
       "    If ``True`` values falling outside the range ``[vmin, vmax]``,\n",
       "    are mapped to 0 or 1, whichever is closer, and masked values are\n",
       "    set to 1.  If ``False`` masked values remain masked.\n",
       "\n",
       "    Clipping silently defeats the purpose of setting the over, under,\n",
       "    and masked colors in a colormap, so it is likely to lead to\n",
       "    surprises; therefore the default is ``clip=False``.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Returns 0 if ``vmin == vmax``.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/bert_analyzer/lib/python3.8/site-packages/matplotlib/colors.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     TwoSlopeNorm, CenteredNorm, FuncNorm, LogNorm, SymLogNorm, PowerNorm, BoundaryNorm, NoNorm\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors.Normalize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04665fe5-8988-4c85-85cb-6287877c3c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
